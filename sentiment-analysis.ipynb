{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python36964bit1cea69b2233644e59d0aa89b42c110e3",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Sentiment Analysis"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Vader Lexicon to accomodate financial vocabulary"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Stock Market Lexicon (https://github.com/nunomroliveira/stock_market_lexicon/blob/master/stock_lex.csv)\n",
    "stock_lex = pd.read_csv('lex_data/stock_lex.csv')\n",
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4\n",
    "\n",
    "# # Loughran McDonald Lexicon ()\n",
    "positive = []\n",
    "with open('lex_data/positive.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        positive.append(row[0].strip())\n",
    "    \n",
    "negative = []\n",
    "with open('lex_data/negative.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        entry = row[0].strip().split(\" \")\n",
    "        if len(entry) > 1:\n",
    "            negative.extend(entry)\n",
    "        else:\n",
    "            negative.append(entry[0])\n",
    "\n",
    "final_lex = {}\n",
    "final_lex.update({word:2.0 for word in positive})\n",
    "final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sia.lexicon)\n",
    "sia.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Vader to retrieve sentiment score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that determine data collection criteria\n",
    "keywords = 'oil'\n",
    "from_date = '3/2/2020' \n",
    "to_date = '3/30/2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "date_sentiments = {}\n",
    "\n",
    "for i in range(1,11):\n",
    "    page = urlopen('https://www.businesstimes.com.sg/search/facebook?page='+str(i)).read()\n",
    "    soup = BeautifulSoup(page, features=\"html.parser\")\n",
    "    posts = soup.findAll(\"div\", {\"class\": \"media-body\"})\n",
    "    for post in posts:\n",
    "        time.sleep(1)\n",
    "        url = post.a['href']\n",
    "        date = post.time.text\n",
    "        print(date, url)\n",
    "        try:\n",
    "            link_page = urlopen(url).read()\n",
    "        except:\n",
    "            url = url[:-2]\n",
    "            link_page = urlopen(url).read()\n",
    "        link_soup = BeautifulSoup(link_page)\n",
    "        sentences = link_soup.findAll(\"p\")\n",
    "        passage = \"\"\n",
    "        for sentence in sentences:\n",
    "            passage += sentence.text\n",
    "        sentiment = sia.polarity_scores(passage)['compound']\n",
    "        date_sentiments.setdefault(date, []).append(sentiment)\n",
    "\n",
    "date_sentiment = {}\n",
    "\n",
    "for k,v in date_sentiments.items():\n",
    "    date_sentiment[datetime.strptime(k, '%d %b %Y').date() + timedelta(days=1)] = round(sum(v)/float(len(v)),3)\n",
    "\n",
    "earliest_date = min(date_sentiment.keys())\n",
    "\n",
    "print(date_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.google.com/search?hl=en&gl=us&tbm=nws&authuser=0&num=20&q=oil&tbs=cdr:1,cd_min:3/31/2020,cd_max:3/31/2020,sbd:1\nhttps://finance.yahoo.com/news/oil-sell-off-pauses-market-221740570.html\n-0.9952\nhttps://www.nytimes.com/2020/03/31/business/energy-environment/crude-oil-companies-coronavirus.html\n-0.9564\nhttps://www.washingtonpost.com/business/2020/03/31/cheap-oil-doesnt-mean-much-when-no-ones-going-anywhere-coronavirus-will-reshape-oil-industry/\n0.958\nhttp://www.marketwatch.com/story/crude-prices-rebound-after-tapping-18-year-low-2020-03-31\n-0.9524\nhttps://finance.yahoo.com/news/putin-trump-agree-current-oil-123751435.html\n-0.9789\nhttps://www.reuters.com/article/us-oil-opec-trump-putin/putin-and-trump-agree-oil-market-situation-suits-neither-kremlin-idUSKBN21I1PS\n-0.3204\nhttps://apnews.com/7c40ef427c3ad91708b602b8c8be615d\n-0.128\nhttps://www.aljazeera.com/ajimpact/oil-prices-crashed-keystone-xl-moving-200331153048908.html\n-0.8791\nhttps://www.investing.com/news/commodities-news/worst-quarter-dawns-on-oil-some-russian-reprieve-2126911\n-0.1779\nhttps://oilprice.com/Latest-Energy-News/World-News/Oil-Major-Faces-800-Million-In-Write-Downs-As-Price-War-Escalates.html\n-0.6908\nhttps://finance.yahoo.com/news/uk-fuel-prices-see-record-plunge-as-coronavirus-saps-oil-demand-135314018.html\n-0.9954\nhttps://en.mercopress.com/2020/03/31/russia-s-oil-giant-rosneft-yields-to-us-pressure-ceases-operations-in-venezuela\n0.9053\nhttps://oilprice.com/Energy/Crude-Oil/Texas-Oil-Drillers-Prepare-To-Halt-Production.html\n-0.9587\nhttps://www.fxstreet.com/news/oil-demand-projections-continue-to-move-lower-tds-202003311038\n-0.9875\nhttps://finance.yahoo.com/news/change-payout-strategy-hour-big-122112210.html\n0.9847\nhttps://www.arkansasonline.com/news/2020/mar/31/oil-prices-plummet-to-lowest-since-02-2/\n-0.9899\nhttps://www.nasdaq.com/articles/tuesday-sector-leaders%3A-oil-gas-exploration-production-oil-gas-equipment-services-2020-03\n0.9749\nhttps://www.nytimes.com/2020/03/31/business/coronavirus-stock-market-updates.html\n0.9977\nhttps://www.npr.org/2020/03/31/822597631/plastic-wars-three-takeaways-from-the-fight-over-the-future-of-plastics\n0.9198\nhttps://www.fool.com/investing/2020/03/31/why-oil-stocks-are-bouncing-back-today.aspx\n0.4777\n-0.18962500000000004\n"
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "\n",
    "def get_news(keywords, date):\n",
    "    url = \"https://www.google.com/search?hl=en&gl=us&tbm=nws&authuser=0&num=20&q=\" + keywords + \"&tbs=cdr:1,cd_min:\" + date + \",cd_max:\" + date + \",sbd:1\"\n",
    "    print(url)\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'\n",
    "    hdrs = {'User-Agent': user_agent} \n",
    "    response = requests.get(url, headers=hdrs)\n",
    "    file1 = open('MyFile.html', 'w+')\n",
    "    file1.write(response.text)\n",
    "    file1.close()\n",
    "    soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "    result_div = soup.find_all('div', attrs = {'class': 'dbsr'})\n",
    "\n",
    "    links = []\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    for r in result_div:\n",
    "        # Checks if each element is present, else, raise exception\n",
    "        try:\n",
    "            link = r.find('a', href = True)\n",
    "            # title = r.find('div', attrs={'class':'vvjwJb'}).get_text()\n",
    "            # description = r.find('div', attrs={'class':'s3v9rd'}).get_text()\n",
    "\n",
    "            # print(link)\n",
    "            \n",
    "            # Check to make sure everything is present before appending\n",
    "            if link != '': \n",
    "                # links.append((link['href'].split('=')[1]).split('&')[0])\n",
    "                links.append(link['href'])\n",
    "                # titles.append(title)\n",
    "                # descriptions.append(description)\n",
    "\n",
    "        # Next loop if one element is not present\n",
    "        except:\n",
    "            print('hello')\n",
    "            continue\n",
    "    return links\n",
    "\n",
    "news_urls = get_news(keywords=keywords, date='3/31/2020')\n",
    "\n",
    "with open('urls.txt', 'a') as url_file:\n",
    "    url_file.write('3/31/2020\\n\\n')\n",
    "    url_file.writelines(\"%s\\n\" % u for u in news_urls)\n",
    "    url_file.write('\\n\\n')\n",
    "\n",
    "sentiment_sum = 0\n",
    "\n",
    "for url in news_urls:\n",
    "    print(url)\n",
    "    link_page = requests.get(url)\n",
    "    link_soup = BeautifulSoup(link_page.text)\n",
    "    sentences = link_soup.findAll(\"p\")\n",
    "    passage = \"\"\n",
    "    for sentence in sentences:\n",
    "        passage += sentence.text\n",
    "    senti = sia.polarity_scores(passage)['compound']\n",
    "    print(senti)\n",
    "    sentiment_sum += senti\n",
    "    # date_sentiments.setdefault(date, []).append(sentiment)\n",
    "\n",
    "print(sentiment_sum)\n",
    "sentiment_sum /= len(news_urls)\n",
    "\n",
    "print(sentiment_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}