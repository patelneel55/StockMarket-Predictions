{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bite80dfb4df88d4ad880f434ea722d8ae8",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Collection\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values can be changed to the requested ticker and parameters \n",
    "\n",
    "ticker = 'GS'\n",
    "from_date = '2010-01-01'\n",
    "to_date = '2018-12-31'\n",
    "type = 'line'\n",
    "\n",
    "competitors = ['JPM', 'MS', 'C', 'BCS', 'CS', 'UBS', 'DB']\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Helper: Financial API helper functions    #\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "# Get JSON data from the requested url\n",
    "def get_json_data(url):\n",
    "    response = urlopen(url)\n",
    "    response = response.read().decode(\"utf-8\")\n",
    "    return json.loads(response)\n",
    "\n",
    "# Conver the provided parameters into FMP url\n",
    "def get_url(ticker, from_date = None, to_date = None, type = None):\n",
    "    url = \"https://financialmodelingprep.com/api/v3/historical-price-full/\" + urllib.parse.quote(ticker, safe='=:/&?') + \"?\"\n",
    "    \n",
    "    params = ''\n",
    "    if from_date != None:\n",
    "        params += 'from=' + from_date + \"&\"\n",
    "    if to_date != None:\n",
    "        params += 'to=' + to_date + '&'\n",
    "    if type != None:\n",
    "        params += 'serietype=' + type + '&'\n",
    "\n",
    "    return url + urllib.parse.quote(params[:-1], safe='=:/&?')\n",
    "\n",
    "json_data = get_json_data(get_url(ticker, from_date, to_date, type))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Write ticker data to file as csv #\n",
    "import csv\n",
    "\n",
    "# Write JSON data to csv file\n",
    "data_file = open('dataset.csv', 'w+')\n",
    "outputWriter = csv.writer(data_file, delimiter=',')\n",
    "\n",
    "outputWriter.writerow(['date', ticker])\n",
    "for obj in json_data['historical']:\n",
    "    outputWriter.writerow([obj['date'] , obj['close']])\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Preprocessing\n",
    "---\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposedly all imports\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from mxnet import nd, autograd, gluon\n",
    "# from mxnet.gluon import nn, rnn\n",
    "# import mxnet as mx\n",
    "import datetime\n",
    "# import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# import math\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are 2264 number of days in the dataset.\nNumber of training days: 1584. Number of test days: 680.\n"
    }
   ],
   "source": [
    "complete_dataset = pd.read_csv('dataset.csv')\n",
    "total_days = complete_dataset.shape[0]\n",
    "num_training_days = int(total_days * .7)\n",
    "num_testing_days = total_days-num_training_days\n",
    "print('There are {} number of days in the dataset.'.format(complete_dataset.shape[0]))\n",
    "print('Number of training days: {}. Number of test days: {}.'.format(num_training_days, num_testing_days))\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Print timeseries of data #\n",
    "\n",
    "# plt.figure(figsize=(14, 5), dpi=100)\n",
    "# plt.plot(complete_dataset['date'], complete_dataset[ticker], label='{ticker} stock')\n",
    "# plt.vlines(str(datetime.date(2016, 4, 20)), 0, 270, linestyles='--', colors='gray', label='Train/Test data cut-off')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('USD')\n",
    "# plt.title('Figure 2: Goldman Sachs stock price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Appends additional features to main data file #\n",
    "\n",
    "def merge_data(json_data):\n",
    "    diff1 = pd.read_csv('dataset.csv')\n",
    "    diff2 = pd.DataFrame(json_data)\n",
    "\n",
    "    diff = diff1.merge(diff2, on=diff1.columns.intersection(diff2.columns).to_numpy().tolist(), right_index=False, left_index=True, how='left')\n",
    "    diff.to_csv('dataset.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Assets\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Companies or Competitors"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are 2264 number of days in the dataset.\n"
    }
   ],
   "source": [
    "# Add similar companies data to dataset #\n",
    "\n",
    "json_data = None\n",
    "\n",
    "for c in competitors:\n",
    "    json_data = get_json_data(get_url(c, from_date, to_date, type))\n",
    "    \n",
    "    # Change 'close' to the company name\n",
    "    json_data = json_data['historical']\n",
    "    for i in range(len(json_data)):\n",
    "        json_data[i][c] = json_data[i].pop('close')\n",
    "\n",
    "    merge_data(json_data)\n",
    "\n",
    "complete_dataset = pd.read_csv('dataset.csv')\n",
    "print('There are {} number of days in the dataset.'.format(complete_dataset.shape[0]))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility Index"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are 2264 number of days in the dataset.\n"
    }
   ],
   "source": [
    "# Add volatility index to the dataset #\n",
    "\n",
    "json_data = None\n",
    "\n",
    "json_data = get_json_data(get_url('index/^VIX', from_date, to_date, type))\n",
    "\n",
    "# Change 'close' to the volatility index\n",
    "json_data = json_data['historical']\n",
    "for i in range(len(json_data)):\n",
    "    json_data[i]['^VIX'] = json_data[i].pop('close')\n",
    "\n",
    "merge_data(json_data)\n",
    "\n",
    "complete_dataset = pd.read_csv('dataset.csv')\n",
    "print('There are {} number of days in the dataset.'.format(complete_dataset.shape[0]))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Economic Indices"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite Indices (S&P500, DOW, NASDAQ, BSE Sensex, FTSE100, Nikkei225)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are 2264 number of days in the dataset.\n"
    }
   ],
   "source": [
    "# Add major worldwide indexes to dataset #\n",
    "\n",
    "major_indices = ['^DJI', '^IXIC', '^GSPC', '^BSESN', '^FTSE', '^N225', '^HSI', '^BVSP', '^BUK100P', '^N100']\n",
    "\n",
    "json_data = None\n",
    "\n",
    "for ind in major_indices:\n",
    "    json_data = get_json_data(get_url('index/' + ind, from_date, to_date, type))\n",
    "   \n",
    "    # Change 'close' to the volatility index\n",
    "    json_data = json_data['historical']\n",
    "    for i in range(len(json_data)):\n",
    "        json_data[i][ind] = json_data[i].pop('close')\n",
    "\n",
    "    merge_data(json_data)\n",
    "\n",
    "complete_dataset = pd.read_csv('dataset.csv')\n",
    "print('There are {} number of days in the dataset.'.format(complete_dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currencies"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "There are 2264 number of days in the dataset.\n"
    }
   ],
   "source": [
    "\n",
    "# Add ForEx data to dataset\n",
    "\n",
    "currencies = ['USDJPY', 'USDGBP', 'USDEUR', 'USDCHF', 'USDCAD']\n",
    "\n",
    "json_data = None\n",
    "\n",
    "for c in currencies:\n",
    "    json_data = get_json_data(get_url('forex/' + c, from_date, to_date, type))\n",
    "\n",
    "    # Change 'close' to the volatility index\n",
    "    json_data = json_data['historical']\n",
    "    for i in range(len(json_data)):\n",
    "        json_data[i][c] = json_data[i].pop('close')\n",
    "\n",
    "    merge_data(json_data)\n",
    "\n",
    "complete_dataset = pd.read_csv('dataset.csv')\n",
    "print('There are {} number of days in the dataset.'.format(complete_dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Indicators\n",
    "---\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_technical_indicators(dataset):\n",
    "    # Create 7 and 21 days Moving Average\n",
    "    dataset['ma7'] = dataset['GS'].rolling(window=7).mean()\n",
    "    dataset['ma21'] = dataset['GS'].rolling(window=21).mean()\n",
    "    \n",
    "    # Create MACD\n",
    "    dataset['26ema'] = dataset['GS'].ewm(span=26).mean()\n",
    "    dataset['12ema'] = dataset['GS'].ewm(span=12).mean()\n",
    "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
    "\n",
    "    # Create Bollinger Bands\n",
    "    dataset['20sd'] = dataset['GS'].rolling(window=20).std()\n",
    "    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
    "    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
    "    \n",
    "    # Create Exponential moving average\n",
    "    dataset['ema'] = dataset['GS'].ewm(com=0.5).mean()\n",
    "    \n",
    "    # Create Momentum\n",
    "    dataset['momentum'] = dataset['GS'] - 1\n",
    "    dataset['log_momentum'] = np.log(dataset['momentum'])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "technical_dataset = get_technical_indicators(complete_dataset[['GS']])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_technical_indicators(dataset, last_days):\n",
    "    plt.figure(figsize=(16, 10), dpi=100)\n",
    "    shape_0 = dataset.shape[0]\n",
    "    xmacd_ = shape_0-last_days\n",
    "    \n",
    "    dataset = dataset.iloc[-last_days:, :]\n",
    "    x_ = range(3, dataset.shape[0])\n",
    "    x_ =list(dataset.index)\n",
    "    \n",
    "    # Plot first subplot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(dataset['ma7'],label='MA 7', color='g',linestyle='--')\n",
    "    plt.plot(dataset['GS'],label='Closing Price', color='b')\n",
    "    plt.plot(dataset['ma21'],label='MA 21', color='r',linestyle='--')\n",
    "    plt.plot(dataset['upper_band'],label='Upper Band', color='c')\n",
    "    plt.plot(dataset['lower_band'],label='Lower Band', color='c')\n",
    "    plt.fill_between(x_, dataset['lower_band'], dataset['upper_band'], alpha=0.35)\n",
    "    plt.title('Technical indicators for Goldman Sachs - last {} days.'.format(last_days))\n",
    "    plt.ylabel('USD')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot second subplot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('MACD')\n",
    "    plt.plot(dataset['MACD'],label='MACD', linestyle='-.')\n",
    "    plt.hlines(15, xmacd_, shape_0, colors='g', linestyles='--')\n",
    "    plt.hlines(-15, xmacd_, shape_0, colors='g', linestyles='--')\n",
    "    plt.plot(dataset['log_momentum'],label='Momentum', color='b',linestyle='-')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_technical_indicators(technical_dataset, 400)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Analysis\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Analysis"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend Analysis\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_dataset = complete_dataset[['date', 'GS']]\n",
    "\n",
    "close_fft = np.fft.fft(np.asarray(fourier_dataset['GS'].tolist()))\n",
    "fft = pd.DataFrame({'fft':close_fft})\n",
    "fft['absolute'] = fft['fft'].apply(lambda x: np.abs(x))\n",
    "fft['angle'] = fft['fft'].apply(lambda x: np.angle(x))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "fft_list = np.asarray(fft['fft'].tolist())\n",
    "for num_ in [3, 6, 9, 100]:\n",
    "    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))\n",
    "plt.plot(fourier_dataset['GS'],  label='Real')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('USD')\n",
    "plt.title('Figure 3: Goldman Sachs (close) stock prices & Fourier transforms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}